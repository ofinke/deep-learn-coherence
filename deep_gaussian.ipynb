{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning Gaussian Function\n",
    "\n",
    "This notebook aims to create basic neural network to recognise sigma of 1D gaussian function with semi-random  gaussian noise and shift along the x axis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow.keras as keras\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from gauss import gauss\r\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create training data\n",
    "1. 1D gaussian function\n",
    "2. Different sigma values defined by ```unique``` variable\n",
    "3. Each unique sigma value is repeated by ```repeats``` number of time. Each copy is modulated with different gaussian noise\n",
    "4. Each instance of the function is randomly shifted along the x axis using numpy ```default.rng().uniform()``` function\n",
    "5. In resulting matrix, one row correspond to one instance of gaussian function\n",
    "6. Rows are randomly mixed to ensure proper training of the network."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ns = True # noise on/off\r\n",
    "length = 256\r\n",
    "# x vector\r\n",
    "x = np.linspace(-10,10,length)\r\n",
    "# number of unique sigma value\r\n",
    "unique = 50\r\n",
    "# number of repeats of each sigma value\r\n",
    "repeats = 1000\r\n",
    "param = np.linspace(0.2,3,unique) # define sigma range\r\n",
    "# descriptor id\r\n",
    "desc = np.arange(unique)\r\n",
    "if repeats != 0:\r\n",
    "    param = np.repeat(param, repeats)\r\n",
    "    desc = np.repeat(desc, repeats)\r\n",
    "    xshift = np.random.default_rng().uniform(low=-5.0, high=5.0, size=(unique*repeats)) # define x shift\r\n",
    "else:\r\n",
    "    xshift = np.zeros(unique)\r\n",
    "# define dataframe of parameters\r\n",
    "param = pd.DataFrame(data={\"sigma\": param, \"xshift\": xshift, \"id\": desc})\r\n",
    "\r\n",
    "# create numpy array with data\r\n",
    "data = np.zeros((param.shape[0], x.shape[0]))\r\n",
    "for i in param.index:\r\n",
    "    data[i,:] = gauss(x, sigma=param.loc[i, \"sigma\"], xshift=param.loc[i, \"xshift\"], noise=ns)\r\n",
    "\r\n",
    "# randomly mix parameters and use mixed index vector as a mask to get corresponding data\r\n",
    "param = param.reindex(np.random.permutation(param.index))\r\n",
    "permuted = data[param.index]\r\n",
    "\r\n",
    "display(param)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess the data\n",
    "* Scalling data using ```MinMaxScaler()```, where each data on specific point x is scaled to <0,1> vector.\n",
    "* Splitting data for trainning and testing using ```train_test_split()```. test_size is set to 20%. Used data needs to be transformed and masked with the permutation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting up scaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "scaler.fit(permuted)\r\n",
    "transformed = scaler.transform(permuted)\r\n",
    "\r\n",
    "# dividing data into training and testing set\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(transformed, param[\"sigma\"].to_numpy(), test_size=0.2)\r\n",
    "\r\n",
    "# print resulting shape of the data for confirmation\r\n",
    "print(x_train.shape)\r\n",
    "print(y_train.shape)\r\n",
    "print(x_test.shape)\r\n",
    "print(y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Model\n",
    "* Building the NN model\n",
    "* Fitting the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# keras.backend.set_floatx('float64')\r\n",
    "\r\n",
    "inputs = keras.Input(shape=(length,))\r\n",
    "l = keras.layers.Dense(length, activation=\"relu\")(inputs)\r\n",
    "l = keras.layers.Dense(length, activation=\"relu\")(l)\r\n",
    "outputs = keras.layers.Dense(1)(l)\r\n",
    "\r\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"lol\")\r\n",
    "# model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# training the model\r\n",
    "model.compile(\r\n",
    "    loss = keras.losses.MeanAbsoluteError(),\r\n",
    "    optimizer = keras.optimizers.Adam(),\r\n",
    "    metrics = [\"accuracy\"],\r\n",
    ")\r\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_split = 0.2, verbose=1)\r\n",
    "\r\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)\r\n",
    "print(\"Test loss:\", scores[0])\r\n",
    "print(\"Test accuracy:\", scores[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5), ncols=1)\r\n",
    "ax.plot(history.history[\"loss\"], label=\"loss\")\r\n",
    "ax.plot(history.history['val_loss'], label=\"val_loss\")\r\n",
    "ax.grid()\r\n",
    "ax.legend()\r\n",
    "\r\n",
    "# ax[1].plot(history.history[\"accuracy\"])\r\n",
    "# ax[1].plot(history.history[\"val_accuracy\"])\r\n",
    "# ax[1].grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting results\n",
    "1. Set sigma and xshift, create gaussian function ```ggo``` accordingly\n",
    "2. Transform ```ggo``` using the created scaler and pass it into the network\n",
    "3. Gather sigma prediction\n",
    "4. For comparison, plot original gaussian function and generated function based on prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ts = 2.49\r\n",
    "xs = np.random.default_rng().uniform(low=-5.0, high=5.0)\r\n",
    "ggo = gauss(x, sigma=ts, xshift=xs, noise=ns)\r\n",
    "\r\n",
    "sigma_pred = model.predict(scaler.transform(np.array([ggo])))[0][0]\r\n",
    "diff = ((np.abs(sigma_pred-ts))/ts)*100\r\n",
    "print(\"Predicted sigma is: \"+str(np.round(sigma_pred,3))+\", which is \"+str(np.round(diff,2))+\"% difference from the original.\")\r\n",
    "\r\n",
    "# compare result with prediction\r\n",
    "fig, ax = plt.subplots(figsize=(8,5), ncols=1)\r\n",
    "ax.plot(x, ggo, label=\"input\")\r\n",
    "ax.plot(x, gauss(x, sigma=sigma_pred,  xshift=xs, noise=False), label=\"prediction\")\r\n",
    "ax.set(xlabel=\"x [-]\", ylabel=\"y [-]\")\r\n",
    "ax.legend()\r\n",
    "\r\n",
    "# fig.savefig(\"nn_test.png\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49fa3baea1e085733ea68167034f3b7630ef2d9a978b15689306e87087071167"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('matlab_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}